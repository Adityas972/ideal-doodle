# -*- coding: utf-8 -*-
"""chronic kidney disease detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zWq17YDhJobgpxBOcErwjcFMXnyaWZWz
"""

import numpy as np
import pandas as pd

data=pd.read_csv('/content/kidney_disease.csv')
data.head()

"""# New section"""

data.info()

data['classification'].value_counts()

data['classification']=data['classification'].replace('ckd\t','ckd')
data['classification'].value_counts()

data=data.drop(['id'],axis=1)
data=data.drop_duplicates()
data.info()

data['dm'].replace(to_replace = {'\tno':'no','\tyes':'yes',' yes':'yes'},inplace=True)

data['cad'] = data['cad'].replace(to_replace = '\tno', value='no')
data['pcv'] = pd.to_numeric(data['pcv'], errors='coerce')
data['wc'] = pd.to_numeric(data['wc'], errors='coerce')
data['rc'] = pd.to_numeric(data['rc'], errors='coerce')

data["sc"].head()

data.info()

continuous_features = []
discrete_features = []
for i in data:
  if data[i].dtype != 'object':
    continuous_features.append(i)
  else:
    discrete_features.append(i)
continuous_features.remove("su")
continuous_features.remove("al")
discrete_features.append("su")
discrete_features.append("al")
print(continuous_features)
print(discrete_features)

for i in data:
  print(i)
  unique_values = data[i].unique()
  print(unique_values)

data['classification'] = data['classification'].map({'ckd': 1, 'notckd': 0})
data['rbc'] = data['rbc'].map({'normal': 1, 'abnormal': 0})
data['pc'] = data['pc'].map({'normal': 1, 'abnormal': 0})
data['pcc'] = data['pcc'].map({'present': 1, 'notpresent': 0})
data['ba'] = data['ba'].map({'present': 1, 'notpresent': 0})
data['htn'] = data['htn'].map({'yes': 1, 'no': 0})
data['dm'] = data['dm'].map({'yes': 1, 'no': 0})
data['cad'] = data['cad'].map({'yes': 1, 'no': 0})
data['appet'] = data['appet'].map({'good': 1, 'poor': 0})
data['pe'] = data['pe'].map({'yes': 1, 'no': 0})
data['ane'] = data['ane'].map({'yes': 1, 'no': 0})

for i in data:
  print(i)
  unique_values = data[i].unique()
  print(unique_values)

# bu - blood urea
# bgr - blood glucose.
# bp - blood pressure. 80 120
# age.  20  45
# sc - serum creatinine.  0.74 1.35 normal

from sklearn.impute import KNNImputer

# Assuming 'columns_to_impute' is a list containing the column names you want to impute

# Create a subset of the DataFrame containing only the columns you want to impute
data_subset = data[continuous_features]

# Initialize the KNNImputer
imp = KNNImputer(n_neighbors=5)

# Fit and transform the imputer only on the selected columns
data_subset_imputed = imp.fit_transform(data_subset)

# Replace the imputed values back into the original DataFrame
data.loc[:, continuous_features] = data_subset_imputed


data.isnull().sum()

import pandas as pd

def transform_column(range, column_name):
    low_threshold, high_threshold = range

    def categorize_value(value):
        if value < low_threshold:
            return 0
        elif value > high_threshold:
            return 2
        else:
            return 1

    # Applying the categorization function to the DataFrame column
    transformed_values = data[column_name].apply(categorize_value)
    return transformed_values

# Example array and DataFrame column
range_array = [[70, 110], [7, 20], [20, 45], [80, 120], [0.74, 1.35]]  # Array with low and high thresholds
feat_array = ["bgr", "bu", "age", "bp", "sc"]
# Applying the transformation function to the DataFrame column
# transformed_column = transform_column(my_array, 'sc')
for i in range(0, 5):
  data[feat_array[i]] = transform_column(range_array[i], feat_array[i])
  print(feat_array[i])
  print(data[feat_array[i]])

for column_name in discrete_features:
    mode = data[column_name].mode()[0]
    data[column_name] = data[column_name].fillna(mode)

data.isnull().sum()

data.info()

for i in data:

  unique_values = data[i].unique()
  print(unique_values)

import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(20,20))
sns.heatmap(data.corr(),annot=True,cmap='coolwarm')

!pip install pgmpy

from pgmpy.models import BayesianNetwork
from pgmpy.inference import VariableElimination
from pgmpy.estimators import BayesianEstimator

col_list = data.columns.to_list()
col_list.pop()
col_list

# network_structure = [("sg", "classification"),("al", "classification"), ("dm", "classification"), ("htn", "classification"), ("classification", "ane"), ("sod", "sg"), ("bgr", "dm"), ("su", "dm"), ("pcv", "rc"), ("rc", "hemo"), ("hemo", "ane"), ("dm", "htn"), ("bp", "htn"), ("cad", "htn")]
network_structure = [("su", "classification"), ("pc", "classification"), ("classification", "al"), ("classification", "bu"), ("classification", "sc"), ("bp", "classification"), ("age", "su"), ("bgr", "su"), ("dm", "su"), ("age", "bp"), ("ba", "pc"), ("pcc", "pc")]
print(network_structure)

import networkx as nx
import matplotlib.pyplot as plt

edges = [("su", "classification"), ("pc", "classification"), ("classification", "al"), ("classification", "bu"), ("classification", "sc"), ("bp", "classification"), ("age", "su"), ("bgr", "su"), ("dm", "su"), ("age", "bp"), ("ba", "pc"), ("pcc", "pc")]

G = nx.DiGraph()

G.add_edges_from(edges)

pos = {
    "bgr": (0, 2),
    "dm": (0, 0),
    "su": (2, 1),
    "ba": (4, 2),
    "pcc": (4, 0),
    "pc": (6, 1),
    "sc": (8, 2),
    "bu": (8, 0),
    "bp": (10, 1),
    "age": (12, 2),
    "al": (12, 0),
    "classification": (8, 1.5)
}
plt.figure(figsize=(10, 10))

nx.draw(G, pos, with_labels=True, font_weight='bold', node_size=1000, node_color='skyblue', edge_color='gray', arrowsize=20)

plt.show()

model = BayesianNetwork(network_structure)

model.fit(data, estimator=BayesianEstimator)

for cpd in model.get_cpds():
    print("CPD for {}: ".format(cpd.variable))
    print(cpd)
    print("===")

inference = VariableElimination(model)

for i in range(0, 3):
  predicted = inference.query(variables=['classification'], evidence={'bp': data['bp'][i], "pcc": data['pcc'][i]})
  print(predicted)

for i in range(0, 3):
  predicted = inference.query(variables=['classification'], evidence={'bp': data['bp'][i], "pcc": data['pcc'][i]})
  print(predicted)

for i in range(0, 3):
  predicted = inference.query(variables=['classification'], evidence={'bp': data['bp'][i], "pcc": data['pcc'][i]})
  print(predicted)